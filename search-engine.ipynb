{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPVlc6eYDM2czp6Db7se5yi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["A collection of docs on different web-pages"],"metadata":{"id":"H1xSv2NlzJrN"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"HK6J_UdDyQWn","executionInfo":{"status":"ok","timestamp":1720036708160,"user_tz":240,"elapsed":4,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}}},"outputs":[],"source":["docs = [\n","    '''About us. We deliver Artificial Intelligence & Machine Learning\n","       solutions to solve business challenges.''',\n","    '''Contact information. Email [martin davtyan at filament dot ai]\n","       if you have any questions''',\n","    '''Filament Chat. A framework for building and maintaining a scalable\n","       chatbot capability''',\n","]\n"]},{"cell_type":"code","source":["import string\n","import nltk\n","from nltk.tokenize import TreebankWordTokenizer\n","\n","REMOVE_PUNCTUATION_TABLE = str.maketrans({x: None for x in string.punctuation})\n","TOKENIZER = TreebankWordTokenizer()\n","\n","example_doc = docs[1]\n","example_doc_tokenized = TOKENIZER.tokenize(\n","        example_doc.translate(REMOVE_PUNCTUATION_TABLE)\n","        )\n","example_doc_tokenized"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4UAc9TBbzCfB","executionInfo":{"status":"ok","timestamp":1720036715144,"user_tz":240,"elapsed":4417,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"3f763140-4a11-4928-e15a-6b2b5592c2dc"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Contact',\n"," 'information',\n"," 'Email',\n"," 'martin',\n"," 'davtyan',\n"," 'at',\n"," 'filament',\n"," 'dot',\n"," 'ai',\n"," 'if',\n"," 'you',\n"," 'have',\n"," 'any',\n"," 'questions']"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["We can't find any overlapping words between the doc and the user query because the user query might not be capitalised or it may be plural. To solve this issue, we can use stemming which is basically stripping the words of their formatting.\n"],"metadata":{"id":"reycijWGzIGI"}},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","STEMMER = PorterStemmer()\n","\n","example_doc_stemmed = [STEMMER.stem(token) for token in example_doc_tokenized]\n","example_doc_stemmed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LjeE5m7QzBYl","executionInfo":{"status":"ok","timestamp":1720036715144,"user_tz":240,"elapsed":3,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"f120ab01-ed37-41ee-ca32-33d356caeeea"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['contact',\n"," 'inform',\n"," 'email',\n"," 'martin',\n"," 'davtyan',\n"," 'at',\n"," 'filament',\n"," 'dot',\n"," 'ai',\n"," 'if',\n"," 'you',\n"," 'have',\n"," 'ani',\n"," 'question']"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["def tokenize_and_stem(s):\n","    return [STEMMER.stem(t) for t\n","            in TOKENIZER.tokenize(s.translate(REMOVE_PUNCTUATION_TABLE))]\n","query = 'contacts'\n","tokenize_and_stem(query)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IolxNpbXz81N","executionInfo":{"status":"ok","timestamp":1720036715145,"user_tz":240,"elapsed":3,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"6539aa6d-bf7a-4e4a-c4a0-3cff0b9d0673"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['contact']"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Vector-Space Model"],"metadata":{"id":"FgvW1nJa0w6V"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","VECTORIZER = TfidfVectorizer(tokenizer=tokenize_and_stem, stop_words='english')\n","VECTORIZER.fit(docs)\n","sorted_vocab = sorted(VECTORIZER.vocabulary_.items())\n","print(sorted_vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JabWGueDz85y","executionInfo":{"status":"ok","timestamp":1720036716249,"user_tz":240,"elapsed":2,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"de6f692f-548e-45b8-c6b2-3e2fa6a6d444"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[('ai', 0), ('ani', 1), ('artifici', 2), ('build', 3), ('busi', 4), ('capabl', 5), ('challeng', 6), ('chat', 7), ('chatbot', 8), ('contact', 9), ('davtyan', 10), ('deliv', 11), ('dot', 12), ('email', 13), ('filament', 14), ('framework', 15), ('inform', 16), ('intellig', 17), ('learn', 18), ('machin', 19), ('maintain', 20), ('martin', 21), ('question', 22), ('scalabl', 23), ('solut', 24), ('solv', 25)]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["A matrix of TF-Idf scores of all the documents given the query. So, whihc docs match the given query the most. Basically a similarity score btween each doc and the query."],"metadata":{"id":"D-QCo_fx3hyu"}},{"cell_type":"code","source":["query = 'contact email is needed to chat with the client'\n","query_vector = VECTORIZER.transform([query]).todense()\n","query_vector"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gXSX90KOz8_o","executionInfo":{"status":"ok","timestamp":1720036723548,"user_tz":240,"elapsed":341,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"48e60afc-2ce1-45fe-b98f-f4648a961be4"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["matrix([[0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.57735027, 0.        , 0.57735027,\n","         0.        , 0.        , 0.        , 0.57735027, 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        ]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","doc_vectors = VECTORIZER.transform(docs).toarray()\n","# Convert query_vector to a numpy array\n","query_vector = np.asarray(query_vector)\n","similarity = cosine_similarity(query_vector, doc_vectors)\n","similarity"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TcjGAtbg2kse","executionInfo":{"status":"ok","timestamp":1720036725343,"user_tz":240,"elapsed":345,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"36e52316-e697-4e67-bc44-31246dd42dd1"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.        , 0.37309798, 0.2097252 ]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["ranks = (-similarity).argsort(axis=None)\n","ranks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IywSoBVq-KHj","executionInfo":{"status":"ok","timestamp":1720036726517,"user_tz":240,"elapsed":2,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"264ae701-252b-4f76-c732-1c49b0d9a34a"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 2, 0])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["most_relevant_doc = docs[ranks[0]]\n","most_relevant_doc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"jZq0uIr0-KLm","executionInfo":{"status":"ok","timestamp":1720036727760,"user_tz":240,"elapsed":5,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"2889326d-dc8a-4b41-db1a-9587f465a9d3"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Contact information. Email [martin davtyan at filament dot ai]\\n       if you have any questions'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["Our system is returning a chatbot related page given a query that has chatbot word in it.\n","Dict feedback has queries as keys and (document index, feedback value) as its values."],"metadata":{"id":"bjOFJyxu_i3V"}},{"cell_type":"code","source":["feedback = {\n","        'who makes chatbots': [(2, 0.), (0, 1.), (1, 1.), (0, 1.)],\n","        'about page': [(0, 1.)]\n","}\n","similarity = cosine_similarity(VECTORIZER.transform(['who makes chatbots']), doc_vectors)\n","ranks = (-similarity).argsort(axis=None)\n","docs[ranks[0]]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"tkKiE_vK-KN8","executionInfo":{"status":"ok","timestamp":1720036729085,"user_tz":240,"elapsed":3,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"908427a4-f86e-4191-9dbe-ccb194cdc9c7"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Filament Chat. A framework for building and maintaining a scalable\\n       chatbot capability'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["Feedback data includes information about which documents were deemed relevant or irrelevant for previous queries. This data can be used to improve the scoring of documents for new queries."],"metadata":{"id":"GU9doOQCKhdc"}},{"cell_type":"markdown","source":["Positive feedback feature- number of times a document has appeared relevant for a given query.\n","\n","Negative feedback feature - number of time sa given documnet has appeared irrelevant.\n","\n","Increase the score for documents with positive feedback and decrease it for those with negative feedback. If there's no feedback, the features are zero and don't impact the score."],"metadata":{"id":"Ho-eB_CbIDCF"}},{"cell_type":"code","source":["import numpy as np\n","import string\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","query = 'who is making chatbots information'\n","feedback_queries = list(feedback.keys())\n","\n","similarity = cosine_similarity(VECTORIZER.transform([query]),\n","                               VECTORIZER.transform(feedback_queries))\n","similarity\n","\n","\n","\n","max_idx = np.argmax(similarity)\n","feedback_queries[max_idx]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"eTNm4UEALSdt","executionInfo":{"status":"ok","timestamp":1720036886396,"user_tz":240,"elapsed":300,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"29892456-c4f8-4501-93fd-30ef6c261fe1"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'who makes chatbots'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["pos_feedback_doc_idx = [idx for idx, feedback_value\n","                        in feedback[feedback_queries[max_idx]]\n","                        if feedback_value == 1.]\n","pos_feedback_doc_idx\n","\n","[0, 1, 0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ihApD84aL-hT","executionInfo":{"status":"ok","timestamp":1720036889232,"user_tz":240,"elapsed":6,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"36d1ee40-50aa-4f35-fb88-eaaa783fd18b"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 1, 0]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["from collections import Counter\n","\n","counts = Counter(pos_feedback_doc_idx)\n","counts\n","\n","Counter({0: 2, 1: 1})\n","\n","pos_feedback_proportions = {\n","        doc_idx: count / sum(counts.values()) for doc_idx, count in counts.items()\n","}\n","pos_feedback_proportions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s6Vv73J4MFg2","executionInfo":{"status":"ok","timestamp":1720036914890,"user_tz":240,"elapsed":310,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"554f86c0-2b18-483e-b246-9aca0018b8a7"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 0.6666666666666666, 1: 0.3333333333333333}"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["nn_similarity = np.max(similarity)\n","pos_feedback_feature = [nn_similarity * pos_feedback_proportions.get(idx, 0.)\n","                        for idx, _ in enumerate(docs)]\n","pos_feedback_feature"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abGPPPXlMFVx","executionInfo":{"status":"ok","timestamp":1720036935850,"user_tz":240,"elapsed":293,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"5ad28ad7-5307-4f3e-e232-6d9f3fa936f2"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.4714045207910317, 0.23570226039551584, 0.0]"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["# Handling unseen queries\n","\n","if the given query hasn't apperaed before in the search, it becomes difficult to determine the relevance of documents accurately.\n","One solution can be using the nearest neighbour approach, i.e, looking for a previously encountered query that is closest to the new query in terms of similarity. By using the method of TF-IDF to measure the similarity between the new and the past queries.\n","\n","Or use cosine similarity."],"metadata":{"id":"xM3HGuy2Ihe2"}},{"cell_type":"code","source":["class Scorer():\n","    \"\"\" Scores documents for a search query based on tf-idf\n","        similarity and relevance feedback\n","\n","    \"\"\"\n","    def __init__(self, docs):\n","        \"\"\" Initialize a scorer with a collection of documents, fit a\n","            vectorizer and list feature functions\n","\n","        \"\"\"\n","        self.docs = docs\n","\n","        self.vectorizer = TfidfVectorizer(tokenizer=tokenize_and_stem,\n","                                          stop_words='english')\n","        self.doc_tfidf = self.vectorizer.fit_transform(docs)\n","\n","        self.features = [\n","            self._feature_tfidf,\n","            self._feature_positive_feedback,\n","        ]\n","        self.feature_weights = [\n","            1.,\n","            2.,\n","        ]\n","\n","        self.feedback = {}\n","\n","    def score(self, query):\n","        \"\"\" Generic scoring function: for a query output a numpy array\n","            of scores aligned with a document list we initialized the\n","            scorer with\n","\n","        \"\"\"\n","        feature_vectors = [feature(query) for feature\n","                           in self.features]\n","\n","        feature_vectors_weighted = [feature * weight for feature, weight\n","                                    in zip(feature_vectors, self.feature_weights)]\n","        return np.sum(feature_vectors_weighted, axis=0)\n","\n","    def learn_feedback(self, feedback_dict):\n","        \"\"\" Learn feedback in a form of `query` -> (doc index, feedback value).\n","            In real life it would be an incremental procedure updating the\n","            feedback object.\n","\n","        \"\"\"\n","        self.feedback = feedback_dict\n","\n","    def _feature_tfidf(self, query):\n","        \"\"\" TF-IDF feature. Return a numpy array of cosine similarities\n","            between TF-IDF vectors of documents and the query\n","\n","        \"\"\"\n","        query_vector = VECTORIZER.transform([query])\n","        similarity = cosine_similarity(query_vector, self.doc_tfidf)\n","        return similarity.ravel()\n","\n","    def _feature_positive_feedback(self, query):\n","        \"\"\" Positive feedback feature. Search the feedback dict for a query\n","            similar to the given one, then assign documents positive values\n","            if there is positive feedback about them.\n","\n","        \"\"\"\n","        if not self.feedback:\n","            return np.zeros(len(self.docs))\n","\n","        feedback_queries = list(self.feedback.keys())\n","        similarity = cosine_similarity(self.vectorizer.transform([query]),\n","                                       self.vectorizer.transform(feedback_queries))\n","        nn_similarity = np.max(similarity)\n","\n","        nn_idx = np.argmax(similarity)\n","        pos_feedback_doc_idx = [idx for idx, feedback_value in\n","                                self.feedback[feedback_queries[nn_idx]]\n","                                if feedback_value == 1.]\n","\n","        feature_values = {\n","                doc_idx: nn_similarity * count / sum(counts.values())\n","                for doc_idx, count in Counter(pos_feedback_doc_idx).items()\n","        }\n","        return np.array([feature_values.get(doc_idx, 0.)\n","                         for doc_idx, _ in enumerate(self.docs)])"],"metadata":{"id":"12DbOGa7-KQF","executionInfo":{"status":"ok","timestamp":1720037053020,"user_tz":240,"elapsed":332,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["scorer = Scorer(docs)\n","query\n"],"metadata":{"id":"4Bh-MtDI-KVD","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1720037055238,"user_tz":240,"elapsed":327,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"96c57842-c197-4487-bb9a-7e8496039ed0"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'who is making chatbots information'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["scorer.score(query)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkZe2YOAMc5o","executionInfo":{"status":"ok","timestamp":1720037056360,"user_tz":240,"elapsed":4,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"f542087f-a4cf-4624-8f0e-63acab37f510"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.        , 0.22847492, 0.25685987])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["docs[scorer.score(query).argmax()]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"vgwd6eXoMc1r","executionInfo":{"status":"ok","timestamp":1720037076154,"user_tz":240,"elapsed":443,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"6c17903b-07e0-4e3e-e86b-a2abc47fba94"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Filament Chat. A framework for building and maintaining a scalable\\n       chatbot capability'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["scorer.learn_feedback(feedback)\n","scorer.score(query)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tg4jNpDTMcyv","executionInfo":{"status":"ok","timestamp":1720037118045,"user_tz":240,"elapsed":320,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"3052ce0c-581b-4beb-ff4f-b2d56a1cd543"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.94280904, 0.69987944, 0.25685987])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["docs[scorer.score(query).argmax()]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"O0loUxVQMcrQ","executionInfo":{"status":"ok","timestamp":1720037126520,"user_tz":240,"elapsed":331,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"5ca89b68-07d8-443b-a236-69b52959c26a"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'About us. We deliver Artificial Intelligence & Machine Learning\\n       solutions to solve business challenges.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["scorer.feature_weights = [0.6, 0.4]\n","scorer.score(query)\n"],"metadata":{"id":"Phg6BZ7_M_rg","executionInfo":{"status":"ok","timestamp":1720037148095,"user_tz":240,"elapsed":321,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"d850f5b7-9e1f-4c91-e5ee-aa068a2a5c83","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.18856181, 0.23136585, 0.15411592])"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["docs[scorer.score(query).argmax()]"],"metadata":{"id":"3NAO70ZhM_om","executionInfo":{"status":"ok","timestamp":1720037163907,"user_tz":240,"elapsed":326,"user":{"displayName":"gurveen kaur sahni","userId":"03614887740927950746"}},"outputId":"f56c052a-ea2a-406d-f3fd-67d9a1cab857","colab":{"base_uri":"https://localhost:8080/","height":35}},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Contact information. Email [martin davtyan at filament dot ai]\\n       if you have any questions'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":30}]}]}